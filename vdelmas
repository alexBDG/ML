class MyModule(torch.nn.Module):
    def __init__(self):
        super(MyModule, self).__init__()
        self.layer2 = torch.nn.Linear(51*51, 1048)
        self.layer2 = torch.nn.Linear(1048, 10)
        self.f1 = torch.nn.ReLU()
        
    def forward(self, x):
        x = x.view(x.size()[0], -1)
        x = self.f1(self.layer1(x))
        x = self.layer2(x)
        return x
